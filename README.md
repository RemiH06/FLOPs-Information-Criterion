![Build with Love](http://ForTheBadge.com/images/badges/built-with-love.svg)

```ascii
███████╗██╗      ██████╗ ██████╗     ██╗ ██████╗
██╔════╝██║     ██╔═══██╗██╔══██╗    ██║██╔════╝
█████╗  ██║     ██║   ██║██████╔╝    ██║██║     
██╔══╝  ██║     ██║   ██║██╔═══╝     ██║██║     
██║     ███████╗╚██████╔╝██║         ██║╚██████╗
╚═╝     ╚══════╝ ╚═════╝ ╚═╝         ╚═╝ ╚═════╝
       by Hex (@RemiH06)          version 0.3.0
```

![Maintained](https://img.shields.io/badge/Maintained%3F-yes-green.svg?style=for-the-badge)
![MIT](https://img.shields.io/badge/License-MIT-blue.svg?style=for-the-badge)

### General Description
I don't really trust AIC or BIC for some of my models. I understand there are many other criterions out there but I rather create my own for a new kind of comparison that has not been conceived. It makes a count of FLOPS and uses them in some formula I will come up with to determine models and even code efficiency in a fusion between statistics and compsci.

The final version is a library made with only python implementing a not so huge math investigation.

```diff
- This project is currently in testing phase
- Lib functions work with a few libraries.
```

## Installation

1. Here I'll place the installation guide, may turn it into a pip package once I finish

## Features

- For now, you can compare models through FLOPs within basic_usage.py
- Also take a look for more advanced usages within fic_usages.ipynb
- Feel free to stalk the not so beautiful refining method I slothfuly came up with