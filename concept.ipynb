{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59b46aee",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# Criterios de información\n",
    "\n",
    "---\n",
    "\n",
    "**1. AIC (Akaike Information Criterion)**  \n",
    "\n",
    "$$\n",
    "AIC = -2 \\ln(\\hat{L}) + 2k\n",
    "$$\n",
    "\n",
    "- $\\hat{L}$: verosimilitud máxima del modelo  \n",
    "- $k$: número de parámetros  \n",
    "\n",
    "Favorece modelos con buen ajuste, pero penaliza por cantidad de parámetros.  \n",
    "Puede sobreajustar en muestras pequeñas.  \n",
    "Bueno para predicción más que para identificar el modelo \"verdadero\".  \n",
    "\n",
    "---\n",
    "\n",
    "**2. AICc (Corrected AIC)**  \n",
    "\n",
    "$$\n",
    "AIC_c = AIC + \\frac{2k(k+1)}{n-k-1}\n",
    "$$\n",
    "\n",
    "- Corrección del AIC para muestras pequeñas.  \n",
    "- Se recomienda usar AICc cuando $n/k < 40$.  \n",
    "- Evita que AIC seleccione modelos demasiado complejos en datasets pequeños.  \n",
    "\n",
    "---\n",
    "\n",
    "**3. BIC (Bayesian Information Criterion / Schwarz Criterion)**  \n",
    "\n",
    "$$\n",
    "BIC = -2 \\ln(\\hat{L}) + k \\ln(n)\n",
    "$$\n",
    "\n",
    "- Penalización más fuerte que AIC ($\\ln(n)$ en vez de 2).  \n",
    "- Tiende a seleccionar modelos más parsimoniosos (simples).  \n",
    "- Justificación bayesiana: aproxima la evidencia del modelo $P(\\text{datos} \\mid \\text{modelo})$.  \n",
    "- Útil para selección del modelo verdadero (consistente).  \n",
    "\n",
    "---\n",
    "\n",
    "**4. HQIC (Hannan–Quinn Information Criterion)**  \n",
    "\n",
    "$$\n",
    "HQIC = -2 \\ln(\\hat{L}) + 2k \\ln(\\ln(n))\n",
    "$$\n",
    "\n",
    "- Compromiso entre AIC y BIC: penaliza más que AIC, menos que BIC.  \n",
    "- Consistente como BIC ($n \\to \\infty$).  \n",
    "- Poco usado en la práctica, pero aparece en econometría y series de tiempo.  \n",
    "\n",
    "---\n",
    "\n",
    "**5. DIC (Deviance Information Criterion)**  \n",
    "\n",
    "$$\n",
    "DIC = \\overline{D(\\theta)} + p_D\n",
    "$$\n",
    "\n",
    "donde:\n",
    "\n",
    "$$\n",
    "D(\\theta) = -2 \\ln P(\\text{datos} \\mid \\theta)\n",
    "$$\n",
    "\n",
    "- $\\overline{D(\\theta)}$: media posterior de la devianza  \n",
    "- $p_D$: número efectivo de parámetros  \n",
    "\n",
    "Se usa en modelos bayesianos con MCMC.  \n",
    "Penaliza la complejidad de manera más flexible que AIC/BIC.  \n",
    "\n",
    "---\n",
    "\n",
    "**6. WAIC (Watanabe–Akaike Information Criterion)**  \n",
    "\n",
    "$$\n",
    "WAIC = -2 \\sum_{i=1}^n \\ln \\Bigg( \\frac{1}{S} \\sum_{s=1}^S P(y_i \\mid \\theta^{(s)}) \\Bigg) + 2 p_{WAIC}\n",
    "$$\n",
    "\n",
    "- Variante totalmente bayesiana, basada en la densidad predictiva puntual.  \n",
    "- Usa muestras de la posterior $\\theta^{(s)}$.  \n",
    "- Mejor que DIC en modelos jerárquicos o multimodales.  \n",
    "- Aproximación bayesiana al error de predicción esperado.  \n",
    "\n",
    "---\n",
    "\n",
    "**7. LOOIC (Leave-One-Out Information Criterion)**  \n",
    "\n",
    "- Basado en validación cruzada leave-one-out.  \n",
    "- Estima el error predictivo esperado quitando una observación a la vez.  \n",
    "- Más robusto que WAIC en presencia de outliers o mala especificación.  \n",
    "- Computacionalmente costoso, aunque existen aproximaciones eficientes (PSIS-LOO).  \n",
    "\n",
    "---\n",
    "\n",
    "**8. Otros menos comunes**  \n",
    "\n",
    "- **CAIC (Consistent AIC)**: similar a BIC pero penaliza más fuerte.  \n",
    "- **TIC (Takeuchi’s Information Criterion)**: generaliza AIC cuando el modelo está mal especificado.  \n",
    "- **MDL (Minimum Description Length)**: selecciona el modelo que codifique los datos de la forma más eficiente.  \n",
    "\n",
    "---\n",
    "\n",
    "## Resumen comparativo\n",
    "\n",
    "| Criterio | Penalización             | Consistencia | Uso típico |\n",
    "|----------|--------------------------|--------------|------------|\n",
    "| **AIC**  | $2k$                     | No           | Predicción |\n",
    "| **AICc** | $2k +$ corrección        | No           | Predicción en muestras pequeñas |\n",
    "| **BIC**  | $k \\ln(n)$               | Sí           | Selección de modelo verdadero |\n",
    "| **HQIC** | $2k \\ln(\\ln(n))$         | Sí           | Series de tiempo / econometría |\n",
    "| **DIC**  | Posterior + $p_D$        | No siempre   | Modelos bayesianos |\n",
    "| **WAIC** | Bayesiana, predictiva    | Sí (asint.)  | Modelos jerárquicos bayesianos |\n",
    "| **LOOIC**| Validación cruzada       | Sí           | Evaluación predictiva robusta |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb55196",
   "metadata": {},
   "source": [
    "**Idea para “criterio de información con FLOPs”**\n",
    "\n",
    "$$\n",
    "IC_{\\text{FLOP}} = -2 \\ln(\\hat{L}) + \\alpha k + \\beta \\cdot \\log(\\text{FLOPs})\n",
    "$$\n",
    "\n",
    "- \\(\\alpha\\): penalización clásica por parámetros.  \n",
    "- \\(\\beta\\): peso dado al costo computacional.  \n",
    "- \\(\\log(\\text{FLOPs})\\): se usa logaritmo para que el efecto no sea desproporcionado.\n",
    "\n",
    "Esto alinearía la selección de modelo no solo con *qué tan bien explica los datos*, sino también con su **eficiencia computacional**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e35210b",
   "metadata": {},
   "source": [
    "$$\n",
    "IC_{\\text{FLOP}} \\;=\\; -2 \\ln(\\hat{L}) \\;+\\; \\alpha k \\;+\\; \\beta \\cdot \\log(\\text{FLOPs})\n",
    "$$\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
