{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "909bf01b",
   "metadata": {},
   "source": [
    "# $\\color{#dda}{\\text{FIC: FLOPs Information Criterion}}$ \n",
    "## $\\color{#dda}{\\text{(Remi's Information Criterion - RIC)}}$\n",
    "\n",
    "**Autor:** Remi Heredia  \n",
    "**Fecha:** Octubre 2025  \n",
    "**Versión:** 2.0 (Fórmula Paramétrica Optimizada)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca03ec06",
   "metadata": {},
   "source": [
    "## $\\color{#dda}{\\text{1. Motivación}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4e5426",
   "metadata": {},
   "source": [
    "Los criterios de información tradicionales (AIC, BIC, MDL) penalizan la complejidad del modelo mediante el **número de parámetros**. Sin embargo, en deep learning moderno:\n",
    "\n",
    "- Dos modelos con igual número de parámetros pueden tener **complejidad computacional muy diferente**\n",
    "- Un modelo con más parámetros puede ser más eficiente (ej: MobileNet vs ResNet)\n",
    "- La arquitectura (depth, skip connections, etc.) no se refleja en el conteo de parámetros\n",
    "\n",
    "Además, con el avance tecnológico y el uso de modelos tan pesados para la realización de tareas relativamente simples, considero que se debe contemplar el consumo energético. Espero que mi enfoque pueda ser de utilidad para ayudar a mitigar al menos un poco el impacto ambiental que tienen (sobre todo) los modelos más pesados.\n",
    "\n",
    "La optimización de modelos operacionalmente podría ayudar a desarrollar herramientas más compactas y, al menos en materia de NLPs, más del estilo \"sistema experto\" en vez de \"todólogos\" (que es lo que está de moda). La problemática por la que se me ocurrió crear esto fue esencialmente porque quiero hostear mis propios GPTs en monoplacas; Quiero entrenar y testear mis modelos de lenguaje natural sin demasiado poder computacional ni una cantidad ingente de memoria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f60b5d",
   "metadata": {},
   "source": [
    "**Ejemplo ilustrativo:**\n",
    "\n",
    "| Modelo | Parámetros | FLOPs | AIC/BIC | FIC |\n",
    "|--------|-----------|-------|---------|-----|\n",
    "| Modelo A | 10M | 1 GFLOP | Penaliza 10M | Penaliza 10M + 1G |\n",
    "| Modelo B | 10M | 5 GFLOPs | Penaliza 10M (igual) | Penaliza 10M + 5G |\n",
    "\n",
    "**Problema:** AIC y BIC asignan la misma penalización a ambos modelos, ignorando que el Modelo B requiere 5× más cómputo.\n",
    "\n",
    "**Propuesta:** Penalizar la complejidad mediante **FLOPs** además de parámetros, capturando así el costo computacional real de ejecutar el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e159eb35",
   "metadata": {},
   "source": [
    "## $\\color{#dda}{\\text{2. Definición General del FIC}}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662b4383",
   "metadata": {},
   "source": [
    "El **FLOPs Information Criterion (FIC)**, también conocido como **RIC (Remi's Information Criterion porque así me llamo)**, es un criterio de selección de modelos que penaliza tanto el desajuste a los datos como la complejidad computacional medida en FLOPs.\n",
    "\n",
    "**Principio fundamental:**\n",
    "> En producción, los modelos se ejecutan millones de veces. El costo computacional importa tanto como el ajuste estadístico."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769c0a63",
   "metadata": {},
   "source": [
    "## $\\color{#dda}{\\text{3. Relación con Big O y Complejidad Algorítmica}}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688036d4",
   "metadata": {},
   "source": [
    "Para evitar preguntas de complejidad computacional, espacio en memoria y criterios como \"yo elijo modelos en base al tiempo que tardan en correr\", hice una pequeña explicación de por qué la notación *Big O* **NO** se puede aplicar a la clase de modelos con los que se trabaja en la ciencia de datos y el aprendizaje máquina.\n",
    "\n",
    "Explico todo con bolitas y palitos porque no sé qué tan multidisciplinario pueda ser considerado este proyecto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91727297",
   "metadata": {},
   "source": [
    "### $\\color{#dda}{\\text{3.1 Big O vs FLOPs: Diferencias Fundamentales}}$\n",
    "\n",
    "| Aspecto | Big O | FLOPs (FIC) |\n",
    "|---------|-------|-------------|\n",
    "| **Naturaleza** | Teórica/Asintótica | Práctica/Exacta |\n",
    "| **Pregunta** | \"¿Cómo escala con $n$?\" | \"¿Cuántas operaciones?\" |\n",
    "| **Output** | $O(n^2)$, $O(n \\log n)$ | 2,000,000 FLOPs |\n",
    "| **Constantes** | Ignoradas | Contadas exactamente |\n",
    "| **Términos menores** | Ignorados | Incluidos |\n",
    "| **Uso principal** | Análisis de algoritmos | Optimización práctica |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec2cf5d",
   "metadata": {},
   "source": [
    "### $\\color{#dda}{\\text{3.2 Relación Matemática}}$\n",
    "\n",
    "Big O proporciona la **forma funcional** de los FLOPs:\n",
    "\n",
    "$$\n",
    "\\text{Big O: } f(n) = O(g(n)) \\implies \\Phi(f) = c \\cdot g(n) + \\text{términos menores}\n",
    "$$\n",
    "\n",
    "**Donde:**\n",
    "- $\\Phi(f)$ = FLOPs exactos\n",
    "- $c$ = constante que Big O ignora pero FIC captura\n",
    "- $g(n)$ = función de crecimiento (ej: $n^2$, $n^3$)\n",
    "\n",
    "**Ejemplo concreto:**\n",
    "\n",
    "```\n",
    "Multiplicación de matrices (n×n)\n",
    "├─ Big O: O(n³) → \"escala cúbicamente\"\n",
    "└─ FLOPs: 2n³ → para n=100: 2,000,000 operaciones exactas\n",
    "\n",
    "FIC usa el valor exacto (2,000,000), no la forma asintótica\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e346f0c7",
   "metadata": {},
   "source": [
    "### $\\color{#dda}{\\text{3.3 Por Qué Big O No Es Suficiente para Selección de Modelos}}$\n",
    "\n",
    "**Caso 1: Misma complejidad asintótica, diferentes FLOPs**\n",
    "\n",
    "| Operación | Big O | FLOPs reales |\n",
    "|-----------|-------|---------------|\n",
    "| Suma de arrays | $O(n)$ | $n$ |\n",
    "| Producto punto | $O(n)$ | $2n$ |\n",
    "\n",
    "Big O: ambos son $O(n)$ → \"igual complejidad\"  \n",
    "FLOPs: producto punto es 2× más costoso → FIC lo detecta\n",
    "\n",
    "**Caso 2: Constantes multiplicativas grandes**\n",
    "\n",
    "```\n",
    "Algoritmo A: 1000n² operaciones  → O(n²)\n",
    "Algoritmo B: n³ operaciones      → O(n³)\n",
    "\n",
    "Para n=10:\n",
    "├─ Big O dice: \"B es peor (cúbico > cuadrático)\"\n",
    "├─ Algoritmo A: 100,000 FLOPs\n",
    "└─ Algoritmo B: 1,000 FLOPs\n",
    "\n",
    "FIC selecciona B correctamente (100× más eficiente para n=10)\n",
    "```\n",
    "\n",
    "**Caso 3: Términos de orden menor relevantes**\n",
    "\n",
    "$$\n",
    "\\Phi(f) = 2n^3 + 5n^2 + 100n\n",
    "$$\n",
    "\n",
    "- Big O: $O(n^3)$ → ignora $5n^2 + 100n$\n",
    "- Para $n=10$: términos \"menores\" = 1,500 (43% del total!)\n",
    "- FIC: usa 3,500 FLOPs exactos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c422118f",
   "metadata": {},
   "source": [
    "### $\\color{#dda}{\\text{3.4 FIC Captura lo que Big O Ignora}}$\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\text{FIC captura:}\n",
    "\\begin{cases}\n",
    "\\text{Constantes multiplicativas} & (2n^3 \\text{ vs } 5n^3) \\\\\n",
    "\\text{Términos de orden menor} & (n^3 + n^2 \\text{ vs } n^3) \\\\\n",
    "\\text{Costo exacto para } n \\text{ dado} & (1M \\text{ vs } 5M \\text{ FLOPs}) \\\\\n",
    "\\text{Arquitectura real} & (\\text{depth, width, connections})\n",
    "\\end{cases}\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f29fe0",
   "metadata": {},
   "source": [
    "### $\\color{#dda}{\\text{3.5 Complementariedad}}$\n",
    "\n",
    "**Big O y FLOPs son complementarios, no excluyentes:**\n",
    "\n",
    "| Etapa | Herramienta | Uso |\n",
    "|-------|-------------|-----|\n",
    "| **Diseño algorítmico** | Big O | Elegir clase de algoritmo (ej: $O(n\\log n)$ > $O(n^2)$) |\n",
    "| **Implementación** | FLOPs | Comparar implementaciones específicas |\n",
    "| **Optimización** | FLOPs + FIC | Seleccionar arquitectura óptima |\n",
    "| **Deployment** | FLOPs + FIC | Decisión final costo-beneficio |\n",
    "\n",
    "**Workflow recomendado:**\n",
    "\n",
    "```\n",
    "1. Big O → Elegir familia de algoritmos\n",
    "   (preferir O(n log n) sobre O(n²) para n grande)\n",
    "   \n",
    "2. FLOPs → Comparar implementaciones concretas\n",
    "   (entre dos O(n²), elegir la de menos FLOPs)\n",
    "   \n",
    "3. FIC → Balancear precisión vs eficiencia\n",
    "   (¿vale la pena 10× más FLOPs por 1% más accuracy?)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f6436d",
   "metadata": {},
   "source": [
    "### $\\color{#dda}{\\text{3.6 Ejemplo en Deep Learning}}$\n",
    "\n",
    "**Comparación ResNet vs MobileNet:**\n",
    "\n",
    "```\n",
    "Big O (ambos):\n",
    "├─ Complejidad: O(H × W × C × D)\n",
    "└─ Conclusión: \"Escalan igual\"\n",
    "\n",
    "FLOPs (diferentes):\n",
    "├─ ResNet-50:    4.1 GFLOPs\n",
    "└─ MobileNetV2:  0.3 GFLOPs\n",
    "└─ Ratio: 13.7× diferencia\n",
    "\n",
    "FIC (considera ambos):\n",
    "├─ ResNet: mejor accuracy (+2%)\n",
    "├─ MobileNet: mucho más eficiente (13.7×)\n",
    "└─ Decisión: ¿2% mejora vale 13.7× más cómputo?\n",
    "    → FIC cuantifica este trade-off\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fad986",
   "metadata": {},
   "source": [
    "## $\\color{#dda}{\\text{4. Fórmula Principal (Versión 2.0 o algo así - Paramétrica)}}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c556294d",
   "metadata": {},
   "source": [
    "$$\n",
    "\\boxed{\n",
    "\\text{FIC} = -2\\log \\mathcal{L}(\\hat{\\theta}|\\mathcal{D}) + \\alpha \\left[\\lambda \\log(\\Phi(f)) + (1-\\lambda)\\frac{\\Phi(f)}{10^6}\\right] + \\beta \\cdot k\n",
    "}\n",
    "$$\n",
    "\n",
    "### Variables Principales:\n",
    "\n",
    "| Variable | Nombre | Descripción | Unidades | Rango típico |\n",
    "|----------|--------|-------------|----------|---------------|\n",
    "| $\\text{FIC}$ | FIC score | Valor del criterio (menor = mejor) | real | $[0, \\infty)$ |\n",
    "| $\\mathcal{L}(\\hat{\\theta}\\|\\mathcal{D})$ | Verosimilitud | Probabilidad de datos dado modelo | $[0, 1]$ | - |\n",
    "| $\\hat{\\theta}$ | Parámetros | Estimaciones MLE/MAP | vector $\\mathbb{R}^k$ | - |\n",
    "| $\\mathcal{D}$ | Datos | Dataset $\\{(x_i, y_i)\\}_{i=1}^n$ | conjunto | - |\n",
    "| $\\Phi(f)$ | FLOPs | Operaciones de punto flotante | entero | $10^3$ - $10^{12}$ |\n",
    "| $f$ | Modelo | Función $f: \\mathcal{X} \\to \\mathcal{Y}$ | función | - |\n",
    "| $\\alpha$ | Peso FLOPs | Penalización computacional | real $\\geq 0$ | 2.0 - 10.0 |\n",
    "| $\\lambda$ | Balance log/linear | Mezcla términos FLOPs | $[0, 1]$ | 0.2 - 0.5 |\n",
    "| $\\beta$ | Peso parámetros | Penalización paramétrica | real $\\geq 0$ | 0.3 - 1.0 |\n",
    "| $k$ | Parámetros | Número de parámetros entrenables | entero | $10^3$ - $10^9$ |\n",
    "| $n$ | Tamaño muestra | Observaciones en $\\mathcal{D}$ | entero | $10^2$ - $10^7$ |\n",
    "\n",
    "### Valores Recomendados (basados en experimentos):\n",
    "\n",
    "| Escenario | $\\alpha$ | $\\beta$ | $\\lambda$ | Uso |\n",
    "|-----------|----------|---------|-----------|-----|\n",
    "| **Móvil/Edge** | 7.0-10.0 | 0.3 | 0.2 | Penaliza fuerte FLOPs |\n",
    "| **Balanceado** | 5.0 | 0.5 | 0.3 | Default recomendado |\n",
    "| **Servidor** | 2.0 | 1.0 | 0.5 | Menos restrictivo |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f899954b",
   "metadata": {},
   "source": [
    "## $\\color{#dda}{\\text{5. Componentes del FIC Explicados}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c06ea0",
   "metadata": {},
   "source": [
    "### $\\color{#dda}{\\text{5.1 Bondad de Ajuste (Término de Verosimilitud)}}$\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{\\text{term}} = -2\\log \\mathcal{L}(\\hat{\\theta}|\\mathcal{D})\n",
    "$$\n",
    "\n",
    "**¿Qué mide?** Qué tan bien el modelo explica los datos observados.\n",
    "\n",
    "**Interpretación:**\n",
    "- **Menor valor** → mejor ajuste a los datos\n",
    "- Es idéntico al término de ajuste en AIC/BIC\n",
    "- No penaliza complejidad, solo mide precisión\n",
    "\n",
    "**Variables específicas:**\n",
    "\n",
    "| Variable | Descripción |\n",
    "|----------|-------------|\n",
    "| $\\log \\mathcal{L}(\\hat{\\theta}\\|\\mathcal{D})$ | Log-verosimilitud del modelo en los datos |\n",
    "| Factor -2 | Convención estadística (escala de deviance) |\n",
    "\n",
    "#### Para Regresión:\n",
    "$$\n",
    "-2\\log \\mathcal{L} = n\\log\\left(\\frac{\\text{RSS}}{n}\\right) + n\\log(2\\pi) + n\n",
    "$$\n",
    "\n",
    "| Variable | Descripción |\n",
    "|----------|-------------|\n",
    "| $\\text{RSS}$ | $\\sum_{i=1}^n (y_i - \\hat{y}_i)^2$ (suma residuos cuadrados) |\n",
    "| $y_i$ | Valor observado |\n",
    "| $\\hat{y}_i$ | Predicción del modelo |\n",
    "\n",
    "#### Para Clasificación:\n",
    "$$\n",
    "-2\\log \\mathcal{L} = -2\\sum_{i=1}^{n} \\log P(y_i|x_i, \\hat{\\theta})\n",
    "$$\n",
    "\n",
    "| Variable | Descripción |\n",
    "|----------|-------------|\n",
    "| $P(y_i\\|x_i, \\hat{\\theta})$ | Probabilidad asignada a clase correcta |\n",
    "| Rango | $[0, 1]$ por observación |\n",
    "\n",
    "**Por qué importa:** Un modelo que predice mal tendrá -2log(L) alto, penalizándolo automáticamente incluso si es eficiente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56abeef",
   "metadata": {},
   "source": [
    "### $\\color{#dda}{\\text{5.2 Término de Penalización Computacional (REMI PERO QUÉ NOVEDOSO)}}$\n",
    "\n",
    "$$\n",
    "\\mathcal{C}_{\\text{comp}} = \\alpha \\left[\\lambda \\log(\\Phi(f)) + (1-\\lambda)\\frac{\\Phi(f)}{10^6}\\right]\n",
    "$$\n",
    "\n",
    "**¿Qué mide?** Costo computacional real de ejecutar el modelo.\n",
    "\n",
    "**Por qué es híbrido (log + lineal)?**\n",
    "\n",
    "| Componente | Fórmula | Sensibilidad | Cuándo domina |\n",
    "|------------|---------|--------------|----------------|\n",
    "| **Logarítmico** | $\\lambda \\log(\\Phi)$ | Diferencias relativas | FLOPs pequeños/medios |\n",
    "| **Lineal** | $(1-\\lambda)\\frac{\\Phi}{10^6}$ | Diferencias absolutas | FLOPs grandes |\n",
    "\n",
    "**Ejemplo numérico:**\n",
    "\n",
    "```python\n",
    "α = 5.0, λ = 0.3\n",
    "\n",
    "Modelo A: 1M FLOPs\n",
    "├─ Término log:    0.3 × log(1,000,000) ≈ 4.14\n",
    "├─ Término lineal: 0.7 × 1.0 = 0.7\n",
    "└─ Penalización:   5.0 × (4.14 + 0.7) = 24.2\n",
    "\n",
    "Modelo B: 10M FLOPs (10× más)\n",
    "├─ Término log:    0.3 × log(10,000,000) ≈ 4.84  (+0.7)\n",
    "├─ Término lineal: 0.7 × 10.0 = 7.0  (+6.3)\n",
    "└─ Penalización:   5.0 × (4.84 + 7.0) = 59.2  (+35.0)\n",
    "\n",
    "Diferencia: 35 puntos de penalización\n",
    "→ El término lineal detecta la diferencia de 9M FLOPs\n",
    "→ El término log suaviza para no sobre-penalizar\n",
    "```\n",
    "\n",
    "**Parámetro $\\lambda$ (balance):**\n",
    "\n",
    "| $\\lambda$ | Comportamiento | Uso |\n",
    "|-----------|----------------|-----|\n",
    "| 1.0 | 100% logarítmico | Diferencias relativas (ej: 10×) |\n",
    "| 0.5 | Balance 50/50 | Propósito general |\n",
    "| 0.3 | 70% lineal | **Recomendado**: detecta diferencias absolutas |\n",
    "| 0.0 | 100% lineal | Penalización muy agresiva |\n",
    "\n",
    "**Variables específicas:**\n",
    "\n",
    "| Variable | Descripción | Cálculo |\n",
    "|----------|-------------|---------|\n",
    "| $\\Phi(f)$ | FLOPs totales | Automático vía `flop_counter` |\n",
    "| $\\alpha$ | Peso global | Controla cuánto importan FLOPs vs ajuste |\n",
    "| $\\lambda$ | Balance | Mezcla sensibilidad relativa/absoluta |\n",
    "| $10^6$ | Normalización | Escala a MegaFLOPs para el término lineal |\n",
    "\n",
    "**Cálculo de $\\Phi(f)$ según operación:**\n",
    "\n",
    "#### Multiplicación de Matrices ($A \\in \\mathbb{R}^{m \\times k}$, $B \\in \\mathbb{R}^{k \\times n}$):\n",
    "$$\n",
    "\\Phi_{\\text{matmul}} = 2mnk\n",
    "$$\n",
    "\n",
    "#### Convolución 2D:\n",
    "$$\n",
    "\\Phi_{\\text{conv2d}} = 2 \\cdot H' \\cdot W' \\cdot C_{\\text{out}} \\cdot C_{\\text{in}} \\cdot K_h \\cdot K_w\n",
    "$$\n",
    "\n",
    "| Variable | Descripción |\n",
    "|----------|-------------|\n",
    "| $H', W'$ | Dimensiones de salida |\n",
    "| $C_{\\text{in}}, C_{\\text{out}}$ | Canales entrada/salida |\n",
    "| $K_h, K_w$ | Tamaño del kernel |\n",
    "\n",
    "#### Red Feed-Forward (L capas):\n",
    "$$\n",
    "\\Phi_{\\text{NN}} = 2\\sum_{l=1}^{L} d_{l-1} \\cdot d_l\n",
    "$$\n",
    "\n",
    "| Variable | Descripción |\n",
    "|----------|-------------|\n",
    "| $d_l$ | Neuronas en capa $l$ |\n",
    "\n",
    "**Por qué importa:** \n",
    "- AIC/BIC ignoran completamente este término\n",
    "- Dos modelos con igual # de parámetros pero diferentes FLOPs son equivalentes para AIC/BIC\n",
    "- FIC los distingue correctamente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d838ad0",
   "metadata": {},
   "source": [
    "### $\\color{#dda}{\\text{5.3 Término de Penalización Paramétrica}}$\n",
    "\n",
    "$$\n",
    "\\mathcal{C}_{\\text{param}} = \\beta \\cdot k\n",
    "$$\n",
    "\n",
    "**¿Qué mide?** Complejidad del modelo en términos de capacidad de expresión.\n",
    "\n",
    "**Interpretación:**\n",
    "- Previene overfitting (muchos parámetros → sobreajuste)\n",
    "- Correlaciona con uso de memoria (más params → más RAM)\n",
    "- Idéntico al término de penalización en AIC/BIC (y de alguna manera mágica no es plagio :3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1050b65",
   "metadata": {},
   "source": [
    "**Variables:**\n",
    "\n",
    "| Variable | Descripción | Ejemplo |\n",
    "|----------|-------------|----------|\n",
    "| $k$ | Parámetros entrenables | Pesos + biases |\n",
    "| $\\beta$ | Peso de penalización | 0.5 (default), 1.0 (AIC-like) |\n",
    "\n",
    "**Cálculo de $k$ por tipo de modelo:**\n",
    "\n",
    "#### Regresión Lineal:\n",
    "$$\n",
    "k = p + 1\n",
    "$$\n",
    "(p predictores + 1 intercept)\n",
    "\n",
    "#### Red Neuronal:\n",
    "$$\n",
    "k = \\sum_{l=1}^{L} (d_{l-1} \\cdot d_l + d_l)\n",
    "$$\n",
    "(pesos de conexiones + biases)\n",
    "\n",
    "#### CNN:\n",
    "$$\n",
    "k = \\sum_{\\text{capas}} (C_{\\text{in}} \\cdot C_{\\text{out}} \\cdot K_h \\cdot K_w + C_{\\text{out}})\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4243e609",
   "metadata": {},
   "source": [
    "**Por qué $\\beta$ es menor que 1.0 en FIC?**\n",
    "\n",
    "```\n",
    "Configuración tradicional (AIC): β = 2, α = 0\n",
    "→ Solo penaliza parámetros\n",
    "\n",
    "Configuración FIC (recomendada): β = 0.5, α = 5.0\n",
    "→ Da más peso a FLOPs que a parámetros\n",
    "→ Razón: en deployment, cómputo importa más que memoria\n",
    "```\n",
    "\n",
    "**SIN EMBARGO**\n",
    "```\n",
    "Se puede utilizar cualquier proporción, sin importar si β > 1\n",
    "→ Penalizando mucho más los parámetros\n",
    "\n",
    "En realidad, de esta manera también puede contemplarse memoria\n",
    "→ Si nuestro objetivo es no solo reducir la cantidad de costo computacional, sino también memoria\n",
    "→ Pueden darse casos en los que memoria importe más que coste computacional\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76f39a8",
   "metadata": {},
   "source": [
    "Los parámetros de la fórmula que diseñé se basan completamente en lo que se busque ahorrar al elegir un modelo así que, a pesar de que este notebook busque escatimar en poder de cómputo, también se puede usar de forma más \"clásica\" buscando ahorrar en parámetros (y por tanto, en memoria)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba7aa24",
   "metadata": {},
   "source": [
    "## $\\color{#dda}{\\text{6. Configuraciones del FIC}}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd13a25",
   "metadata": {},
   "source": [
    "Basándome en los resultados del notebook de refinado (fic_refining.ipynb) y los experimentos que hice, llegué a la conclusión de que los parámetros dependerán un poco de los modelos a optimizar o comparar. De todas formas dejo algunos combos que me gustaron porque demostraron poder usarse de forma más general y balanceada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536ee23f",
   "metadata": {},
   "source": [
    "### $\\color{#dda}{\\text{6.1 FIC-Balanceado (Recomendado)}}$\n",
    "\n",
    "$$\n",
    "\\text{FIC}_{\\text{bal}} = -2\\log \\mathcal{L} + 5.0 \\left[0.3\\log(\\Phi)+ 0.7\\frac{\\Phi}{10^6}\\right] + 0.5k\n",
    "$$\n",
    "\n",
    "**Configuración:**\n",
    "\n",
    "| Parámetro | Valor | Razón |\n",
    "|-----------|-------|-------|\n",
    "| $\\alpha$ | 5.0 | Penalización moderada-alta de FLOPs |\n",
    "| $\\beta$ | 0.5 | Menos peso a parámetros (FLOPs más críticos) |\n",
    "| $\\lambda$ | 0.3 | 30% log, 70% lineal (detecta diferencias grandes) |\n",
    "\n",
    "**Uso:** Default para producción. Balance entre precisión y eficiencia.\n",
    "\n",
    "**Expandida:**\n",
    "$$\n",
    "\\text{FIC}_{\\text{bal}} = -2\\log \\mathcal{L} + 1.5\\log(\\Phi) + 3.5\\frac{\\Phi}{10^6} + 0.5k\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd7b9a4",
   "metadata": {},
   "source": [
    "### $\\color{#dda}{\\text{6.2 FIC-Móvil (Muy Restrictivo)}}$\n",
    "\n",
    "$$\n",
    "\\text{FIC}_{\\text{móvil}} = -2\\log \\mathcal{L} + 10.0 \\left[0.2\\log(\\Phi) + 0.8\\frac{\\Phi}{10^6}\\right] + 0.3k\n",
    "$$\n",
    "\n",
    "**Configuración:**\n",
    "\n",
    "| Parámetro | Valor | Razón |\n",
    "|-----------|-------|-------|\n",
    "| $\\alpha$ | 10.0 | Penalización muy agresiva de FLOPs |\n",
    "| $\\beta$ | 0.3 | Mínimo peso a parámetros |\n",
    "| $\\lambda$ | 0.2 | 80% lineal (muy sensible a FLOPs absolutos) |\n",
    "\n",
    "**Uso:** Móviles, edge devices, IoT. Batería y latencia son críticas.\n",
    "\n",
    "**Expandida:**\n",
    "$$\n",
    "\\text{FIC}_{\\text{móvil}} = -2\\log \\mathcal{L} + 2.0\\log(\\Phi) + 8.0\\frac{\\Phi}{10^6} + 0.3k\n",
    "$$\n",
    "\n",
    "**Efecto:** Modelo con 10M FLOPs vs 1M FLOPs tiene penalización adicional de ~72 puntos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8426492",
   "metadata": {},
   "source": [
    "### $\\color{#dda}{\\text{6.3 FIC-Servidor (Menos Restrictivo)}}$\n",
    "\n",
    "$$\n",
    "\\text{FIC}_{\\text{servidor}} = -2\\log \\mathcal{L} + 2.0 \\left[0.5\\log(\\Phi) + 0.5\\frac{\\Phi}{10^6}\\right] + 1.0k\n",
    "$$\n",
    "\n",
    "**Configuración:**\n",
    "\n",
    "| Parámetro | Valor | Razón |\n",
    "|-----------|-------|-------|\n",
    "| $\\alpha$ | 2.0 | Penalización suave (análoga a AIC) |\n",
    "| $\\beta$ | 1.0 | Peso completo a parámetros |\n",
    "| $\\lambda$ | 0.5 | Balance 50/50 |\n",
    "\n",
    "**Uso:** Servidores con recursos abundantes. Precisión es prioridad.\n",
    "\n",
    "**Expandida:**\n",
    "$$\n",
    "\\text{FIC}_{\\text{servidor}} = -2\\log \\mathcal{L} + 1.0\\log(\\Phi) + 1.0\\frac{\\Phi}{10^6} + 1.0k\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2e5192",
   "metadata": {},
   "source": [
    "### $\\color{#dda}{\\text{6.4 Comparación Visual}}$\n",
    "\n",
    "```\n",
    "Modelo A: 1M FLOPs, 100K params, -2log(L) = 1000\n",
    "Modelo B: 10M FLOPs, 100K params, -2log(L) = 990\n",
    "\n",
    "Análisis:\n",
    "├─ Modelo B es 1% mejor en ajuste (990 vs 1000)\n",
    "└─ Modelo B es 10× más costoso (10M vs 1M FLOPs)\n",
    "\n",
    "Configuración Móvil (α=10, λ=0.2):\n",
    "├─ FIC(A) = 1000 + 2.0×log(1M) + 8.0×1.0 + 30 = 1065.8\n",
    "├─ FIC(B) = 990 + 2.0×log(10M) + 8.0×10.0 + 30 = 1135.8\n",
    "└─ Δ = +70 → Selecciona A (B no vale la pena)\n",
    "\n",
    "Configuración Servidor (α=2, λ=0.5):\n",
    "├─ FIC(A) = 1000 + 1.0×log(1M) + 1.0×1.0 + 100 = 1114.8\n",
    "├─ FIC(B) = 990 + 1.0×log(10M) + 1.0×10.0 + 100 = 1116.3\n",
    "└─ Δ = +1.5 → Ambos comparables\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea3aa5a",
   "metadata": {},
   "source": [
    "## $\\color{#dda}{\\text{7. Selección de Modelo}}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35556950",
   "metadata": {},
   "source": [
    "### $\\color{#dda}{\\text{7.1 Criterio de Decisión}}$\n",
    "\n",
    "Dado un conjunto de modelos candidatos $\\mathcal{F} = \\{f_1, f_2, \\ldots, f_M\\}$:\n",
    "\n",
    "$$\n",
    "f^* = \\arg\\min_{f \\in \\mathcal{F}} \\text{FIC}(f)\n",
    "$$\n",
    "\n",
    "**Variables:**\n",
    "\n",
    "| Variable | Descripción |\n",
    "|----------|-------------|\n",
    "| $\\mathcal{F}$ | Conjunto de modelos candidatos |\n",
    "| $M$ | Número de modelos |\n",
    "| $f^*$ | Modelo óptimo (menor FIC) |\n",
    "\n",
    "**Principio:** Menor FIC = mejor balance entre ajuste, eficiencia y simplicidad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f952f1",
   "metadata": {},
   "source": [
    "### $\\color{#dda}{\\text{7.2 Diferencia de FIC (ΔFIC)}}$\n",
    "\n",
    "Para comparar dos modelos $f_1$ y $f_2$:\n",
    "\n",
    "$$\n",
    "\\Delta\\text{FIC} = \\text{FIC}(f_1) - \\text{FIC}(f_2)\n",
    "$$\n",
    "\n",
    "**Interpretación (Guidelines de Burnham & Anderson):**\n",
    "\n",
    "| $|\\Delta\\text{FIC}|$ | Evidencia | Decisión |\n",
    "|-------------------|-----------|----------|\n",
    "| 0 - 2 | Sustancialmente equivalentes | Ambos modelos comparables |\n",
    "| 2 - 10 | Evidencia considerable | Preferir modelo con menor FIC |\n",
    "| > 10 | Evidencia muy fuerte | Modelo con mayor FIC es claramente inferior |\n",
    "\n",
    "**Ejemplo práctico:**\n",
    "\n",
    "```\n",
    "FIC(MLP) = 1000\n",
    "FIC(CNN) = 1005\n",
    "\n",
    "ΔFIC = 5 → Evidencia considerable contra CNN\n",
    "Interpretación: CNN no justifica su complejidad adicional\n",
    "Decisión: Usar MLP\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9374d5b3",
   "metadata": {},
   "source": [
    "## $\\color{#dda}{\\text{8. Estimación de Hiperparámetros α, β, λ}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7469edda",
   "metadata": {},
   "source": [
    "### $\\color{#dda}{\\text{8.1 Mediante Validación Cruzada}}$\n",
    "\n",
    "$$\n",
    "(\\alpha^*, \\beta^*, \\lambda^*) = \\arg\\min_{(\\alpha, \\beta, \\lambda) \\in \\Lambda} \\text{CV-Error}(\\alpha, \\beta, \\lambda)\n",
    "$$\n",
    "\n",
    "**Espacio de búsqueda:**\n",
    "$$\n",
    "\\Lambda = \\{(\\alpha, \\beta, \\lambda) : \\alpha \\in [0.5, 10], \\beta \\in [0, 2], \\lambda \\in [0, 1]\\}\n",
    "$$\n",
    "\n",
    "**Procedimiento:**\n",
    "\n",
    "1. Definir grids:\n",
    "   - $\\alpha \\in \\{0.5, 1.0, 2.0, 5.0, 7.0, 10.0\\}$\n",
    "   - $\\beta \\in \\{0.0, 0.3, 0.5, 1.0, 2.0\\}$\n",
    "   - $\\lambda \\in \\{0.0, 0.2, 0.3, 0.4, 0.5, 0.8, 1.0\\}$\n",
    "\n",
    "2. Para cada combinación:\n",
    "   - Calcular FIC de todos los modelos\n",
    "   - Seleccionar mejor modelo según FIC\n",
    "   - Evaluar en validación\n",
    "\n",
    "3. Elegir $(\\alpha^*, \\beta^*, \\lambda^*)$ que minimizan error de validación\n",
    "\n",
    "**Implementación:** Ver `fic_parameter_optimization.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f19f704",
   "metadata": {},
   "source": [
    "### $\\color{#dda}{\\text{8.2 Valores Recomendados (Empíricos)}}$\n",
    "\n",
    "Basados en experimentos con 3 tipos de problemas:\n",
    "\n",
    "| Escenario | $\\alpha$ | $\\beta$ | $\\lambda$ | Sensibilidad |\n",
    "|-----------|----------|---------|-----------|---------------|\n",
    "| **Regresión** | 5.0 | 0.5 | 0.3 | Alta (ΔFIC ~25) |\n",
    "| **Redes Neuronales** | 5.0 | 0.5 | 0.3 | Media (ΔFIC ~150) |\n",
    "| **Polinomios** | 5.0 | 0.5 | 0.3 | Muy alta (ΔFIC ~700) |\n",
    "\n",
    "**Conclusión:** $(\\alpha=5.0, \\beta=0.5, \\lambda=0.3)$ es robusto across diferentes problemas.\n",
    "\n",
    "**Alternativas por analogía:**\n",
    "\n",
    "#### Análoga a AIC:\n",
    "$$\n",
    "\\alpha = 2.0, \\quad \\beta = 0.0, \\quad \\lambda = 0.5\n",
    "$$\n",
    "\n",
    "#### Análoga a BIC:\n",
    "$$\n",
    "\\alpha = \\log(n), \\quad \\beta = 0.0, \\quad \\lambda = 0.5\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d11a21",
   "metadata": {},
   "source": [
    "## $\\color{#dda}{\\text{9. Propiedades Matemáticas del FIC}}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfae043",
   "metadata": {},
   "source": [
    "### $\\color{#dda}{\\text{9.1 Consistencia Asintótica}}$\n",
    "\n",
    "**Definición:** El FIC es consistente si selecciona el modelo verdadero cuando $n \\to \\infty$:\n",
    "\n",
    "$$\n",
    "\\lim_{n \\to \\infty} P(\\text{FIC selecciona } f_0) = 1\n",
    "$$\n",
    "\n",
    "**Condiciones suficientes:**\n",
    "- $\\alpha = o(\\sqrt{n})$ → penalización crece más lento que $\\sqrt{n}$\n",
    "- $\\beta = o(\\sqrt{n})$\n",
    "- $f_0 \\in \\mathcal{F}$ → modelo verdadero está en candidatos\n",
    "\n",
    "**Interpretación:** Con suficientes datos, FIC encuentra el modelo correcto."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cdddae",
   "metadata": {},
   "source": [
    "### $\\color{#dda}{\\text{9.2 Invarianza a Escala de FLOPs}}$\n",
    "\n",
    "Si transformamos FLOPs por constante $c > 0$:\n",
    "\n",
    "$$\n",
    "\\Phi'(f) = c \\cdot \\Phi(f)\n",
    "$$\n",
    "\n",
    "Entonces:\n",
    "\n",
    "$$\n",
    "\\text{FIC}'(f) = \\text{FIC}(f) + \\alpha\\lambda\\log(c) + \\alpha(1-\\lambda)\\frac{c-1}{10^6}\\Phi(f)\n",
    "$$\n",
    "\n",
    "**Conclusión:** El **ranking relativo** se preserva (todos los modelos se desplazan igual).\n",
    "\n",
    "**Implicación práctica:** No importa si contamos FLOPs con o sin ciertos overheads, el orden de modelos no cambia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a4c122",
   "metadata": {},
   "source": [
    "## $\\color{#dda}{\\text{10. Casos de Uso Específicos}}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b731ad",
   "metadata": {},
   "source": [
    "### $\\color{#dda}{\\text{10.1 Regresión Lineal}}$\n",
    "\n",
    "**Modelo:**\n",
    "$$\n",
    "y_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i, \\quad \\epsilon_i \\sim \\mathcal{N}(0, \\sigma^2)\n",
    "$$\n",
    "\n",
    "**FIC:**\n",
    "$$\n",
    "\\text{FIC} = n\\log(\\text{RSS}) + \\alpha\\left[\\lambda\\log(3np) + (1-\\lambda)\\frac{3np}{10^6}\\right] + \\beta \\cdot 2\n",
    "$$\n",
    "\n",
    "**Variables:**\n",
    "\n",
    "| Variable | Valor | Explicación |\n",
    "|----------|-------|-------------|\n",
    "| $3np$ | FLOPs | $2np$ (matmul) + $np$ (residuos) |\n",
    "| $k$ | 2 | $\\beta_0, \\beta_1$ |\n",
    "| RSS | $\\sum(y_i - \\hat{y}_i)^2$ | Suma residuos cuadrados |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd6623c",
   "metadata": {},
   "source": [
    "### $\\color{#dda}{\\text{10.2 Red Neuronal Feed-Forward}}$\n",
    "\n",
    "**Arquitectura:** $[d_0, d_1, d_2, \\ldots, d_L]$\n",
    "\n",
    "**FIC:**\n",
    "$$\n",
    "\\text{FIC} = -2\\sum_{i=1}^n \\log P(y_i|x_i) + \\alpha\\left[\\lambda\\log\\left(2\\sum_{l=1}^L d_{l-1}d_l\\right) + (1-\\lambda)\\frac{2\\sum_{l=1}^L d_{l-1}d_l}{10^6}\\right] + \\beta\\sum_{l=1}^L (d_{l-1}d_l + d_l)\n",
    "$$\n",
    "\n",
    "**Componentes:**\n",
    "\n",
    "| Término | Fórmula | Interpretación |\n",
    "|---------|---------|----------------|\n",
    "| FLOPs | $2\\sum d_{l-1}d_l$ | Todas las multiplicaciones matriz-vector |\n",
    "| Parámetros | $\\sum (d_{l-1}d_l + d_l)$ | Pesos + biases |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c7b7f1",
   "metadata": {},
   "source": [
    "### $\\color{#dda}{\\text{10.3 Red Convolucional (CNN)}}$\n",
    "\n",
    "**Para una capa convolucional:**\n",
    "\n",
    "$$\n",
    "\\Phi_{\\text{conv}} = 2H'W'C_{\\text{out}}C_{\\text{in}}K_hK_w\n",
    "$$\n",
    "\n",
    "$$\n",
    "k_{\\text{conv}} = C_{\\text{out}} \\cdot C_{\\text{in}} \\cdot K_h \\cdot K_w + C_{\\text{out}}\n",
    "$$\n",
    "\n",
    "**FIC de la capa:**\n",
    "$$\n",
    "\\text{FIC}_{\\text{capa}} = \\alpha\\left[\\lambda\\log(\\Phi_{\\text{conv}}) + (1-\\lambda)\\frac{\\Phi_{\\text{conv}}}{10^6}\\right] + \\beta \\cdot k_{\\text{conv}}\n",
    "$$\n",
    "\n",
    "**Para arquitectura completa:**\n",
    "$$\n",
    "\\text{FIC}_{\\text{CNN}} = -2\\log \\mathcal{L} + \\alpha\\left[\\lambda\\log\\left(\\sum_{\\text{capas}} \\Phi\\right) + (1-\\lambda)\\frac{\\sum_{\\text{capas}} \\Phi}{10^6}\\right] + \\beta\\sum_{\\text{capas}} k\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b52f44b",
   "metadata": {},
   "source": [
    "## $\\color{#dda}{\\text{11. Resumen de Notación Completa}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcd3a3b",
   "metadata": {},
   "source": [
    "| Símbolo | Nombre | Descripción | Tipo | Rango |\n",
    "|---------|--------|-------------|------|-------|\n",
    "| $\\text{FIC}$ | FIC score | Valor del criterio | escalar | $[0, \\infty)$ |\n",
    "| $\\mathcal{L}$ | Verosimilitud | P(datos\\|modelo) | $[0,1]$ | - |\n",
    "| $\\hat{\\theta}$ | Parámetros | Estimaciones MLE | vector | $\\mathbb{R}^k$ |\n",
    "| $\\mathcal{D}$ | Datos | Training set | conjunto | - |\n",
    "| $\\Phi(f)$ | FLOPs | Operaciones FP | entero | $10^3$-$10^{12}$ |\n",
    "| $f$ | Modelo | Función predictiva | función | - |\n",
    "| $\\alpha$ | Peso FLOPs | Penalización comp. | real $\\geq 0$ | 2-10 |\n",
    "| $\\lambda$ | Balance | Mix log/linear | $[0,1]$ | 0.2-0.5 |\n",
    "| $\\beta$ | Peso params | Penalización param. | real $\\geq 0$ | 0.3-1.0 |\n",
    "| $k$ | Parámetros | Dim($\\theta$) | entero | $10^3$-$10^9$ |\n",
    "| $n$ | Muestra | # observaciones | entero | $10^2$-$10^7$ |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e030b0a",
   "metadata": {},
   "source": [
    "## $\\color{#dda}{\\text{12. Fórmula Final (y mis recomendaciones)}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b405643",
   "metadata": {},
   "source": [
    "$$\\color{#ddd}{\\text{Se le pueden poner casi cualquier }{\\alpha, \\beta  \\text{ o }  \\lambda}}$$\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\text{FIC} = -2\\log \\mathcal{L}(\\hat{\\theta}|\\mathcal{D}) + \\alpha \\left[\\lambda \\log(\\Phi(f)) + (1-\\lambda)\\frac{\\Phi(f)}{10^6}\\right] + \\beta \\cdot k\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d29888",
   "metadata": {},
   "source": [
    "$$\\color{#ddd}{\\text{Pero aquí está mi receta para comenzar un análisis de viabilidad computacional}}$$\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\begin{aligned}\n",
    "\\text{FIC} &= -2\\log \\mathcal{L}(\\hat{\\theta}|\\mathcal{D}) + 5.0\\left[0.3\\log(\\Phi(f)) + 0.7\\frac{\\Phi(f)}{10^6}\\right] + 0.5k \\\\\n",
    "&= \\underbrace{-2\\log \\mathcal{L}}_{\\text{ajuste a datos}} + \\underbrace{1.5\\log(\\Phi) + 3.5\\frac{\\Phi}{10^6}}_{\\text{penalización computacional}} + \\underbrace{0.5k}_{\\text{penalización paramétrica}}\n",
    "\\end{aligned}\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976ef648",
   "metadata": {},
   "source": [
    "**Componentes:**\n",
    "1. **Primer término ($-2\\log \\mathcal{L}$):** Mide ajuste (menor = mejor fit)\n",
    "2. **Segundo término ($1.5\\log(\\Phi) + 3.5\\frac{\\Phi}{10^6}$):** Penaliza FLOPs altos\n",
    "   - Parte log: sensible a diferencias relativas\n",
    "   - Parte lineal: sensible a diferencias absolutas\n",
    "3. **Tercer término ($0.5k$):** Penaliza muchos parámetros (overfitting + memoria)\n",
    "\n",
    "**Interpretación unificada:**\n",
    "> Selecciona el modelo que mejor balancea precisión, eficiencia computacional y simplicidad.\n",
    "\n",
    "**Si no vas a usar mi fórmula mínimo ten en cuenta los FLOPs, la electricidad de por sí ya está bien cara**\n",
    "```\n",
    "AIC = -2log(L) + 2k            → Ignora FLOPs completamente\n",
    "BIC = -2log(L) + k·log(n)      → Ignora FLOPs completamente\n",
    "FIC = -2log(L) + f(FLOPs) + βk → Considera FLOPs + parámetros\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
