{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "909bf01b",
   "metadata": {},
   "source": [
    "# $\\color{#dda}{\\text{FIC: FLOPs Information Criterion}}$ \n",
    "## $\\color{#dda}{\\text{(Remi's Information Criterion - RIC)}}$\n",
    "\n",
    "**Autor:** Remi Heredia  \n",
    "**Fecha:** Septiembre 2025  \n",
    "**Versión:** 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca03ec06",
   "metadata": {},
   "source": [
    "## $\\color{#dda}{\\text{1. Motivación}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f60b5d",
   "metadata": {},
   "source": [
    "Los criterios de información tradicionales (AIC, BIC, MDL) penalizan la complejidad del modelo mediante el **número de parámetros**. Sin embargo, en deep learning moderno:\n",
    "\n",
    "- Dos modelos con igual número de parámetros pueden tener **complejidad computacional muy diferente**\n",
    "- Un modelo con más parámetros puede ser más eficiente (ej: MobileNet vs ResNet)\n",
    "- La arquitectura (depth, skip connections, etc.) no se refleja en el conteo de parámetros\n",
    "\n",
    "**Ejemplo ilustrativo:**\n",
    "\n",
    "| Modelo | Parámetros | FLOPs | AIC/BIC |\n",
    "|--------|-----------|-------|---------|\n",
    "| Modelo A | 10M | 1 GFLOP | Penaliza 10M |\n",
    "| Modelo B | 10M | 5 GFLOPs | Penaliza 10M (igual) |\n",
    "\n",
    "**Problema:** AIC y BIC asignan la misma penalización a ambos modelos, ignorando que el Modelo B requiere 5× más cómputo.\n",
    "\n",
    "**Propuesta:** Penalizar la complejidad mediante **FLOPs** en lugar de (o además de) parámetros, capturando así el costo computacional real de ejecutar el modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e159eb35",
   "metadata": {},
   "source": [
    "## $\\color{#dda}{\\text{2. Definición General del FIC}}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662b4383",
   "metadata": {},
   "source": [
    "El **FLOPs Information Criterion (FIC)**, también conocido como **Remi's Information Criterion (RIC)**, es un criterio de selección de modelos que penaliza tanto el desajuste a los datos como la complejidad computacional medida en FLOPs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769c0a63",
   "metadata": {},
   "source": [
    "## $\\color{#dda}{\\text{3. Relación con Big O y Complejidad Algorítmica}}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91727297",
   "metadata": {},
   "source": [
    "### $\\color{#dda}{\\text{3.1 Big O vs FLOPs: Diferencias Fundamentales}}$\n",
    "\n",
    "| Aspecto | Big O | FLOPs (FIC) |\n",
    "|---------|-------|-------------|\n",
    "| **Naturaleza** | Teórica/Asintótica | Práctica/Exacta |\n",
    "| **Pregunta** | \"¿Cómo escala con $n$?\" | \"¿Cuántas operaciones?\" |\n",
    "| **Output** | $O(n^2)$, $O(n \\log n)$ | 2,000,000 FLOPs |\n",
    "| **Constantes** | Ignoradas | Contadas exactamente |\n",
    "| **Términos menores** | Ignorados | Incluidos |\n",
    "| **Uso principal** | Análisis de algoritmos | Optimización práctica |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec2cf5d",
   "metadata": {},
   "source": [
    "### $\\color{#dda}{\\text{3.2 Relación Matemática}}$\n",
    "\n",
    "Big O proporciona la **forma funcional** de los FLOPs:\n",
    "\n",
    "$\n",
    "\\text{Big O: } f(n) = O(g(n)) \\implies \\Phi(f) = c \\cdot g(n) + \\text{términos menores}\n",
    "$\n",
    "\n",
    "**Donde:**\n",
    "- $\\Phi(f)$ = FLOPs exactos\n",
    "- $c$ = constante que Big O ignora\n",
    "- $g(n)$ = función de crecimiento (ej: $n^2$, $n^3$)\n",
    "\n",
    "\n",
    "\n",
    "**Ejemplo concreto:**\n",
    "\n",
    "```\n",
    "Multiplicación de matrices (n×n)\n",
    "├─ Big O: O(n³)\n",
    "└─ FLOPs: 2n³\n",
    "\n",
    "Para n=100:\n",
    "├─ Big O: \"escala cúbicamente\" \n",
    "└─ FLOPs: 2,000,000 operaciones exactas\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e346f0c7",
   "metadata": {},
   "source": [
    "### $\\color{#dda}{\\text{3.3 Por Qué Big O No Es Suficiente para Selección de Modelos}}$\n",
    "\n",
    "**Caso 1: Misma complejidad asintótica, diferentes FLOPs**\n",
    "\n",
    "| Operación | Big O | FLOPs |\n",
    "|-----------|-------|-------|\n",
    "| Suma de arrays | $O(n)$ | $n$ |\n",
    "| Producto punto | $O(n)$ | $2n$ |\n",
    "\n",
    "Ambos son $O(n)$, pero el producto punto requiere **2× más trabajo**.\n",
    "\n",
    "**Caso 2: Constantes multiplicativas grandes**\n",
    "\n",
    "```\n",
    "Algoritmo A: 1000n² operaciones  → O(n²)\n",
    "Algoritmo B: n³ operaciones      → O(n³)\n",
    "\n",
    "Para n=10:\n",
    "├─ Algoritmo A: 100,000 FLOPs (más costoso!)\n",
    "└─ Algoritmo B: 1,000 FLOPs\n",
    "\n",
    "Big O diría: \"B es peor (cúbico vs cuadrático)\"\n",
    "FLOPs dice: \"A es 100× más costoso para n=10\"\n",
    "```\n",
    "\n",
    "**Caso 3: Términos de orden menor relevantes**\n",
    "\n",
    "$\n",
    "\\Phi(f) = 2n^3 + 5n^2 + 100n\n",
    "$\n",
    "\n",
    "- Big O: $O(n^3)$ (ignora $5n^2 + 100n$)\n",
    "- Para $n=10$: \n",
    "  - Término dominante: 2,000\n",
    "  - Términos menores: 500 + 1,000 = 1,500 (43% del total!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c422118f",
   "metadata": {},
   "source": [
    "### $\\color{#dda}{\\text{3.4 FIC Captura lo que Big O Ignora}}$\n",
    "\n",
    "$\n",
    "\\boxed{\n",
    "\\text{FIC captura:}\n",
    "\\begin{cases}\n",
    "\\text{Constantes multiplicativas} & (2n^3 \\text{ vs } 5n^3) \\\\\n",
    "\\text{Términos de orden menor} & (n^3 + n^2 \\text{ vs } n^3) \\\\\n",
    "\\text{Costo exacto para } n \\text{ dado} & (1M \\text{ vs } 5M \\text{ FLOPs})\n",
    "\\end{cases}\n",
    "}\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f29fe0",
   "metadata": {},
   "source": [
    "### $\\color{#dda}{\\text{3.5 Complementariedad}}$\n",
    "\n",
    "**Big O y FLOPs son complementarios, no excluyentes:**\n",
    "\n",
    "- **Big O:** Útil para entender escalabilidad y elegir algoritmos\n",
    "- **FLOPs (FIC):** Útil para optimizar implementaciones y comparar modelos concretos\n",
    "\n",
    "**Workflow recomendado:**\n",
    "\n",
    "```\n",
    "1. Usar Big O para elegir clase de algoritmo\n",
    "   (e.g., preferir O(n log n) sobre O(n²) para n grande)\n",
    "   \n",
    "2. Usar FLOPs/FIC para elegir entre implementaciones\n",
    "   (e.g., entre dos redes O(n²), elegir la de menos FLOPs)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f6436d",
   "metadata": {},
   "source": [
    "### $\\color{#dda}{\\text{3.6 Ejemplo en Deep Learning}}$\n",
    "\n",
    "**Comparación ResNet vs MobileNet:**\n",
    "\n",
    "```\n",
    "Big O (ambos):\n",
    "├─ Entrada: imagen de H×W\n",
    "├─ Salida: clasificación de C clases\n",
    "└─ Complejidad: O(H × W × C)\n",
    "\n",
    "FLOPs (diferentes):\n",
    "├─ ResNet-50:    4.1 GFLOPs\n",
    "└─ MobileNetV2:  0.3 GFLOPs\n",
    "\n",
    "Ratio: 13.7× diferencia!\n",
    "```\n",
    "\n",
    "**Big O dice:** \"Ambos escalan igual\"  \n",
    "**FIC dice:** \"MobileNet es 13.7× más eficiente\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19fad986",
   "metadata": {},
   "source": [
    "## $\\color{#dda}{\\text{4. Fórmula Principal}}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c556294d",
   "metadata": {},
   "source": [
    "$$\n",
    "\\boxed{\n",
    "\\text{FIC} = -2\\log \\mathcal{L}(\\hat{\\theta}|\\mathcal{D}) + \\alpha \\cdot \\log(\\Phi(f)) + \\beta \\cdot k\n",
    "}\n",
    "$$\n",
    "\n",
    "### Variables:\n",
    "\n",
    "| Variable | Nombre | Descripción | Unidades |\n",
    "|----------|--------|-------------|----------|\n",
    "| $\\text{FIC}$ | FIC score | Valor del criterio (menor es mejor) | escalar real |\n",
    "| $\\mathcal{L}(\\hat{\\theta}\\|\\mathcal{D})$ | Verosimilitud | Probabilidad de observar los datos dado el modelo | $[0, 1]$ |\n",
    "| $\\hat{\\theta}$ | Parámetros estimados | Parámetros del modelo optimizados en los datos | vector en $\\mathbb{R}^k$ |\n",
    "| $\\mathcal{D}$ | Datos | Conjunto de entrenamiento $\\{(x_i, y_i)\\}_{i=1}^n$ | - |\n",
    "| $\\Phi(f)$ | FLOPs | Número de operaciones de punto flotante del modelo $f$ | entero positivo |\n",
    "| $f$ | Modelo | Función que mapea entradas a predicciones | $f: \\mathcal{X} \\to \\mathcal{Y}$ |\n",
    "| $\\alpha$ | Peso computacional | Coeficiente de penalización por FLOPs | escalar real, $\\alpha \\geq 0$ |\n",
    "| $\\beta$ | Peso paramétrico | Coeficiente de penalización por parámetros | escalar real, $\\beta \\geq 0$ |\n",
    "| $k$ | Número de parámetros | Dimensión del espacio de parámetros | entero positivo |\n",
    "| $n$ | Tamaño de muestra | Número de observaciones en $\\mathcal{D}$ | entero positivo |\n",
    "\n",
    "### Valores Recomendados:\n",
    "\n",
    "- **$\\alpha = 2$**: Por analogía con AIC (penalización estándar)\n",
    "- **$\\beta = 1$**: Penalización moderada por parámetros\n",
    "- **$\\alpha = 0, \\beta = 0$**: Recupera el criterio de máxima verosimilitud puro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f899954b",
   "metadata": {},
   "source": [
    "## $\\color{#dda}{\\text{5. Componentes del FIC}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c06ea0",
   "metadata": {},
   "source": [
    "### $\\color{#dda}{\\text{5.1 Bondad de Ajuste (Goodness-of-fit)}}$\n",
    "\n",
    "$$\n",
    "\\mathcal{L}_{\\text{term}} = -2\\log \\mathcal{L}(\\hat{\\theta}|\\mathcal{D})\n",
    "$$\n",
    "\n",
    "**Variables específicas:**\n",
    "\n",
    "| Variable | Descripción |\n",
    "|----------|-------------|\n",
    "| $\\log \\mathcal{L}(\\hat{\\theta}\\|\\mathcal{D})$ | Log-verosimilitud del modelo |\n",
    "\n",
    "**Interpretación:**\n",
    "- Mide qué tan bien el modelo explica los datos observados\n",
    "- **Menor valor** → mejor ajuste\n",
    "- Depende del tipo de problema:\n",
    "\n",
    "#### Para Regresión:\n",
    "$$\n",
    "-2\\log \\mathcal{L}(\\hat{\\theta}|\\mathcal{D}) = n\\log\\left(\\frac{\\text{RSS}}{n}\\right) + n\\log(2\\pi) + n\n",
    "$$\n",
    "\n",
    "**Variables:**\n",
    "| Variable | Descripción |\n",
    "|----------|-------------|\n",
    "| $\\text{RSS}$ | Residual Sum of Squares = $\\sum_{i=1}^n (y_i - \\hat{y}_i)^2$ |\n",
    "| $y_i$ | Valor observado de la respuesta para la observación $i$ |\n",
    "| $\\hat{y}_i$ | Predicción del modelo para la observación $i$ |\n",
    "\n",
    "#### Para Clasificación (Cross-Entropy):\n",
    "$$\n",
    "-2\\log \\mathcal{L}(\\hat{\\theta}|\\mathcal{D}) = -2\\sum_{i=1}^{n} \\log P(y_i|x_i, \\hat{\\theta})\n",
    "$$\n",
    "\n",
    "**Variables:**\n",
    "| Variable | Descripción |\n",
    "|----------|-------------|\n",
    "| $P(y_i\\|x_i, \\hat{\\theta})$ | Probabilidad asignada por el modelo a la clase verdadera $y_i$ dado input $x_i$ |\n",
    "| $x_i$ | Vector de características para la observación $i$ |\n",
    "| $y_i$ | Etiqueta verdadera para la observación $i$ |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56abeef",
   "metadata": {},
   "source": [
    "### $\\color{#dda}{\\text{5.2 Término de Penalización Computacional}}$\n",
    "\n",
    "$$\n",
    "\\mathcal{C}_{\\text{comp}} = \\alpha \\cdot \\log(\\Phi(f))\n",
    "$$\n",
    "\n",
    "**Variables específicas:**\n",
    "\n",
    "| Variable | Descripción | Cálculo |\n",
    "|----------|-------------|---------|\n",
    "| $\\Phi(f)$ | FLOPs totales del modelo | Obtenido con `flop_counter.count_model_flops()` |\n",
    "| $\\log(\\Phi(f))$ | Escala logarítmica de FLOPs | Reduce impacto de valores muy grandes |\n",
    "\n",
    "**Casos específicos:**\n",
    "\n",
    "#### Para Multiplicación de Matrices:\n",
    "$$\n",
    "\\Phi_{\\text{matmul}}(A, B) = 2mnk\n",
    "$$\n",
    "\n",
    "**Variables:**\n",
    "| Variable | Descripción |\n",
    "|----------|-------------|\n",
    "| $A \\in \\mathbb{R}^{m \\times k}$ | Primera matriz |\n",
    "| $B \\in \\mathbb{R}^{k \\times n}$ | Segunda matriz |\n",
    "| $m$ | Número de filas de $A$ |\n",
    "| $k$ | Dimensión compartida (columnas de $A$, filas de $B$) |\n",
    "| $n$ | Número de columnas de $B$ |\n",
    "\n",
    "#### Para Convolución 2D:\n",
    "$$\n",
    "\\Phi_{\\text{conv2d}} = 2 \\cdot H' \\cdot W' \\cdot C_{\\text{out}} \\cdot C_{\\text{in}} \\cdot K_h \\cdot K_w\n",
    "$$\n",
    "\n",
    "**Variables:**\n",
    "| Variable | Descripción |\n",
    "|----------|-------------|\n",
    "| $H'$ | Altura del feature map de salida |\n",
    "| $W'$ | Ancho del feature map de salida |\n",
    "| $C_{\\text{out}}$ | Número de canales de salida (filtros) |\n",
    "| $C_{\\text{in}}$ | Número de canales de entrada |\n",
    "| $K_h$ | Altura del kernel |\n",
    "| $K_w$ | Ancho del kernel |\n",
    "\n",
    "#### Para Red Neuronal Feed-Forward:\n",
    "$$\n",
    "\\Phi_{\\text{NN}} = 2\\sum_{l=1}^{L} d_{l-1} \\cdot d_l\n",
    "$$\n",
    "\n",
    "**Variables:**\n",
    "| Variable | Descripción |\n",
    "|----------|-------------|\n",
    "| $L$ | Número de capas |\n",
    "| $d_l$ | Dimensión de la capa $l$ |\n",
    "| $d_0$ | Dimensión de entrada |\n",
    "| $d_L$ | Dimensión de salida |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1050b65",
   "metadata": {},
   "source": [
    "### $\\color{#dda}{\\text{5.3 Término de Penalización Paramétrica}}$\n",
    "\n",
    "$$\n",
    "\\mathcal{C}_{\\text{param}} = \\beta \\cdot k\n",
    "$$\n",
    "\n",
    "**Variables específicas:**\n",
    "\n",
    "| Variable | Descripción |\n",
    "|----------|-------------|\n",
    "| $k$ | Número total de parámetros entrenables en el modelo |\n",
    "| $\\beta$ | Factor de penalización (típicamente $\\beta = 1$ o $\\beta = \\log(n)/2$) |\n",
    "\n",
    "**Cálculo de $k$:**\n",
    "\n",
    "#### Para Regresión Lineal:\n",
    "$$\n",
    "k = p + 1\n",
    "$$\n",
    "\n",
    "**Variables:**\n",
    "| Variable | Descripción |\n",
    "|----------|-------------|\n",
    "| $p$ | Número de predictores |\n",
    "| $+1$ | Término de intercept |\n",
    "\n",
    "#### Para Red Neuronal:\n",
    "$$\n",
    "k = \\sum_{l=1}^{L} (d_{l-1} \\cdot d_l + d_l)\n",
    "$$\n",
    "\n",
    "**Variables:**\n",
    "| Variable | Descripción |\n",
    "|----------|-------------|\n",
    "| $d_{l-1} \\cdot d_l$ | Pesos de la conexión entre capa $l-1$ y $l$ |\n",
    "| $d_l$ | Biases de la capa $l$ |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba7aa24",
   "metadata": {},
   "source": [
    "## $\\color{#dda}{\\text{6. Variantes del FIC}}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536ee23f",
   "metadata": {},
   "source": [
    "### $\\color{#dda}{\\text{6.1 FIC-Estándar (FIC-S)}}$\n",
    "\n",
    "$$\n",
    "\\text{FIC-S} = -2\\log \\mathcal{L}(\\hat{\\theta}|\\mathcal{D}) + 2\\log(\\Phi(f))\n",
    "$$\n",
    "\n",
    "**Variables:**\n",
    "| Variable | Valor | Descripción |\n",
    "|----------|-------|-------------|\n",
    "| $\\alpha$ | $2$ | Análogo a AIC |\n",
    "| $\\beta$ | $0$ | Solo penaliza FLOPs |\n",
    "\n",
    "**Uso:** Cuando la complejidad paramétrica es menos relevante que la computacional."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd7b9a4",
   "metadata": {},
   "source": [
    "### $\\color{#dda}{\\text{6.2 FIC-BIC (FIC con penalización tipo Bayesiana)}}$\n",
    "\n",
    "$$\n",
    "\\text{FIC-BIC} = -2\\log \\mathcal{L}(\\hat{\\theta}|\\mathcal{D}) + \\log(n) \\cdot \\log(\\Phi(f))\n",
    "$$\n",
    "\n",
    "**Variables adicionales:**\n",
    "| Variable | Descripción |\n",
    "|----------|-------------|\n",
    "| $\\log(n)$ | Penalización que crece con el tamaño de muestra |\n",
    "\n",
    "**Uso:** Cuando se dispone de muchos datos y se quiere una penalización más conservadora."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8426492",
   "metadata": {},
   "source": [
    "### $\\color{#dda}{\\text{6.3 FIC-Híbrido (FIC-H)}}$\n",
    "\n",
    "$$\n",
    "\\text{FIC-H} = -2\\log \\mathcal{L}(\\hat{\\theta}|\\mathcal{D}) + 2\\log(\\Phi(f)) + k\n",
    "$$\n",
    "\n",
    "**Variables:**\n",
    "| Variable | Valor |\n",
    "|----------|-------|\n",
    "| $\\alpha$ | $2$ |\n",
    "| $\\beta$ | $1$ |\n",
    "\n",
    "**Uso:** Balance entre complejidad computacional y paramétrica (**RECOMENDADO**)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af2e5192",
   "metadata": {},
   "source": [
    "### $\\color{#dda}{\\text{6.4 FIC-Normalizado (FIC-N)}}$\n",
    "\n",
    "$$\n",
    "\\text{FIC-N} = -2\\log \\mathcal{L}(\\hat{\\theta}|\\mathcal{D}) + \\alpha \\cdot \\frac{\\log(\\Phi(f))}{\\log(n)}\n",
    "$$\n",
    "\n",
    "**Variables adicionales:**\n",
    "| Variable | Descripción |\n",
    "|----------|-------------|\n",
    "| $\\log(n)$ | Factor de normalización por tamaño de muestra |\n",
    "\n",
    "**Uso:** Para comparar modelos entrenados con diferentes tamaños de muestra."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea3aa5a",
   "metadata": {},
   "source": [
    "### $\\color{#dda}{\\text{6.5 FIC-Relativo (FIC-R)}}$\n",
    "\n",
    "$$\n",
    "\\text{FIC-R} = -2\\log \\mathcal{L}(\\hat{\\theta}|\\mathcal{D}) + \\gamma \\cdot \\frac{\\Phi(f)}{\\text{Accuracy}(f)}\n",
    "$$\n",
    "\n",
    "**Variables adicionales:**\n",
    "| Variable | Descripción |\n",
    "|----------|-------------|\n",
    "| $\\gamma$ | Coeficiente de trade-off eficiencia-precisión |\n",
    "| $\\text{Accuracy}(f)$ | Precisión del modelo en conjunto de validación, $\\in [0, 1]$ |\n",
    "\n",
    "**Uso:** Cuando se quiere penalizar modelos que usan muchos FLOPs pero logran poca mejora en precisión."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b117fa15",
   "metadata": {},
   "source": [
    "## $\\color{#dda}{\\text{7. Selección de Modelo}}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35556950",
   "metadata": {},
   "source": [
    "### $\\color{#dda}{\\text{7.1 Criterio de Decisión}}$\n",
    "\n",
    "Dado un conjunto de modelos candidatos $\\mathcal{F} = \\{f_1, f_2, \\ldots, f_M\\}$:\n",
    "\n",
    "$$\n",
    "f^* = \\arg\\min_{f \\in \\mathcal{F}} \\text{FIC}(f)\n",
    "$$\n",
    "\n",
    "**Variables:**\n",
    "| Variable | Descripción |\n",
    "|----------|-------------|\n",
    "| $\\mathcal{F}$ | Conjunto de modelos candidatos |\n",
    "| $M$ | Número de modelos candidatos |\n",
    "| $f^*$ | Modelo óptimo según FIC |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f952f1",
   "metadata": {},
   "source": [
    "### $\\color{#dda}{\\text{7.2 Diferencia de FIC (ΔFIC)}}$\n",
    "\n",
    "Para comparar dos modelos $f_1$ y $f_2$:\n",
    "\n",
    "$$\n",
    "\\Delta\\text{FIC} = \\text{FIC}(f_1) - \\text{FIC}(f_2)\n",
    "$$\n",
    "\n",
    "**Interpretación:**\n",
    "\n",
    "| $\\Delta\\text{FIC}$ | Decisión |\n",
    "|-------------------|----------|\n",
    "| $\\Delta\\text{FIC} < -10$ | Evidencia muy fuerte a favor de $f_1$ |\n",
    "| $-10 \\leq \\Delta\\text{FIC} < -2$ | Evidencia sustancial a favor de $f_1$ |\n",
    "| $-2 \\leq \\Delta\\text{FIC} \\leq 2$ | Ambos modelos son comparables |\n",
    "| $2 < \\Delta\\text{FIC} \\leq 10$ | Evidencia sustancial a favor de $f_2$ |\n",
    "| $\\Delta\\text{FIC} > 10$ | Evidencia muy fuerte a favor de $f_2$ |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9374d5b3",
   "metadata": {},
   "source": [
    "## $\\color{#dda}{\\text{8. Estimación de Hiperparámetros α y β}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7469edda",
   "metadata": {},
   "source": [
    "### $\\color{#dda}{\\text{8.1 Mediante Validación Cruzada}}$\n",
    "\n",
    "$$\n",
    "(\\alpha^*, \\beta^*) = \\arg\\min_{(\\alpha, \\beta) \\in \\Lambda} \\text{CV-Error}(\\alpha, \\beta)\n",
    "$$\n",
    "\n",
    "**Variables:**\n",
    "| Variable | Descripción |\n",
    "|----------|-------------|\n",
    "| $\\Lambda$ | Espacio de búsqueda para hiperparámetros |\n",
    "| $\\text{CV-Error}$ | Error de validación cruzada promedio |\n",
    "\n",
    "**Procedimiento:**\n",
    "\n",
    "1. Definir grid de búsqueda:\n",
    "   $$\n",
    "   \\Lambda = \\{(\\alpha, \\beta) : \\alpha \\in [0, 5], \\beta \\in [0, 5]\\}\n",
    "   $$\n",
    "\n",
    "2. Para cada par $(\\alpha, \\beta)$:\n",
    "   - Calcular $\\text{FIC}(f; \\alpha, \\beta)$ para todos los modelos\n",
    "   - Seleccionar $f^*(\\alpha, \\beta) = \\arg\\min_f \\text{FIC}(f; \\alpha, \\beta)$\n",
    "   - Evaluar error en validación: $e(\\alpha, \\beta)$\n",
    "\n",
    "3. Seleccionar:\n",
    "   $$\n",
    "   (\\alpha^*, \\beta^*) = \\arg\\min_{(\\alpha,\\beta)} e(\\alpha, \\beta)\n",
    "   $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f19f704",
   "metadata": {},
   "source": [
    "### $\\color{#dda}{\\text{8.2 Valores Teóricos por Analogía}}$\n",
    "\n",
    "#### Analogía con AIC:\n",
    "$$\n",
    "\\alpha = 2, \\quad \\beta = 0\n",
    "$$\n",
    "\n",
    "#### Analogía con BIC:\n",
    "$$\n",
    "\\alpha = \\frac{\\log(n)}{2}, \\quad \\beta = 0\n",
    "$$\n",
    "\n",
    "#### Híbrido (Recomendado):\n",
    "$$\n",
    "\\alpha = 2, \\quad \\beta = 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d11a21",
   "metadata": {},
   "source": [
    "## $\\color{#dda}{\\text{9. Propiedades Matemáticas del FIC}}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfae043",
   "metadata": {},
   "source": [
    "### $\\color{#dda}{\\text{9.1 Consistencia}}$\n",
    "\n",
    "**Definición:** El FIC es consistente si:\n",
    "\n",
    "$$\n",
    "\\lim_{n \\to \\infty} P(\\text{FIC selecciona el modelo verdadero } f_0) = 1\n",
    "$$\n",
    "\n",
    "**Variables:**\n",
    "| Variable | Descripción |\n",
    "|----------|-------------|\n",
    "| $f_0$ | Modelo verdadero (generador de datos) |\n",
    "| $P(\\cdot)$ | Probabilidad |\n",
    "\n",
    "**Condiciones suficientes:**\n",
    "- $\\alpha = o(\\sqrt{n})$\n",
    "- $\\beta = o(\\sqrt{n})$\n",
    "- El modelo verdadero está en el conjunto de candidatos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cdddae",
   "metadata": {},
   "source": [
    "### $\\color{#dda}{\\text{9.2 Invarianza a Escala}}$\n",
    "\n",
    "Para una transformación de FLOPs $\\Phi'(f) = c \\cdot \\Phi(f)$ con $c > 0$:\n",
    "\n",
    "$$\n",
    "\\text{FIC}'(f) = -2\\log \\mathcal{L}(\\hat{\\theta}|\\mathcal{D}) + \\alpha \\cdot \\log(c \\cdot \\Phi(f)) + \\beta \\cdot k\n",
    "$$\n",
    "\n",
    "$$\n",
    "= \\text{FIC}(f) + \\alpha \\log(c)\n",
    "$$\n",
    "\n",
    "**Variables:**\n",
    "| Variable | Descripción |\n",
    "|----------|-------------|\n",
    "| $c$ | Constante de escala positiva |\n",
    "| $\\alpha \\log(c)$ | Desplazamiento constante (no afecta ranking de modelos) |\n",
    "\n",
    "**Conclusión:** El ranking relativo de modelos se preserva bajo transformaciones de escala."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a4c122",
   "metadata": {},
   "source": [
    "## $\\color{#dda}{\\text{10. Casos de Uso Específicos}}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b731ad",
   "metadata": {},
   "source": [
    "### $\\color{#dda}{\\text{10.1 Regresión Lineal Simple}}$\n",
    "\n",
    "**Modelo:**\n",
    "$$\n",
    "y_i = \\beta_0 + \\beta_1 x_i + \\epsilon_i, \\quad \\epsilon_i \\sim \\mathcal{N}(0, \\sigma^2)\n",
    "$$\n",
    "\n",
    "**FIC:**\n",
    "$$\n",
    "\\text{FIC} = n\\log(\\text{RSS}) + 2\\log(3np) + 2\n",
    "$$\n",
    "\n",
    "**Variables:**\n",
    "| Variable | Descripción | Valor |\n",
    "|----------|-------------|-------|\n",
    "| $\\text{RSS}$ | Suma de residuos cuadrados | $\\sum_{i=1}^n (y_i - \\hat{y}_i)^2$ |\n",
    "| $3np$ | FLOPs para regresión lineal | $2np$ (producto matriz-vector) + $np$ (residuos) |\n",
    "| $p$ | Número de predictores | En regresión simple, $p=1$ |\n",
    "| $k$ | Parámetros | $k = 2$ ($\\beta_0, \\beta_1$) |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd6623c",
   "metadata": {},
   "source": [
    "### $\\color{#dda}{\\text{10.2 Red Neuronal Multicapa}}$\n",
    "\n",
    "**Arquitectura:** $[d_0, d_1, d_2, \\ldots, d_L]$\n",
    "\n",
    "**FIC:**\n",
    "$$\n",
    "\\text{FIC} = -2\\sum_{i=1}^n \\log P(y_i|x_i) + 2\\log\\left(2\\sum_{l=1}^L d_{l-1}d_l\\right) + \\sum_{l=1}^L (d_{l-1}d_l + d_l)\n",
    "$$\n",
    "\n",
    "**Variables:**\n",
    "| Variable | Descripción |\n",
    "|----------|-------------|\n",
    "| $d_0$ | Dimensión de entrada (features) |\n",
    "| $d_l$ | Número de neuronas en capa $l$ |\n",
    "| $d_L$ | Dimensión de salida (clases o outputs) |\n",
    "| $L$ | Número de capas (profundidad de la red) |\n",
    "| $P(y_i\\|x_i)$ | Softmax output para clasificación o Gaussiana para regresión |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c7b7f1",
   "metadata": {},
   "source": [
    "### $\\color{#dda}{\\text{10.3 Modelo Convolucional (CNN)}}$\n",
    "\n",
    "**Para una sola capa convolucional:**\n",
    "\n",
    "$$\n",
    "\\text{FIC}_{\\text{conv}} = -2\\log \\mathcal{L} + 2\\log(2H'W'C_{\\text{out}}C_{\\text{in}}K_hK_w) + (C_{\\text{out}} \\cdot C_{\\text{in}} \\cdot K_h \\cdot K_w + C_{\\text{out}})\n",
    "$$\n",
    "\n",
    "**Variables:**\n",
    "| Variable | Descripción | Rango típico |\n",
    "|----------|-------------|--------------|\n",
    "| $H', W'$ | Dimensiones espaciales de salida | Depende de stride y padding |\n",
    "| $C_{\\text{in}}$ | Canales de entrada | RGB: 3, grayscale: 1 |\n",
    "| $C_{\\text{out}}$ | Número de filtros | 16-512 típicamente |\n",
    "| $K_h, K_w$ | Tamaño del kernel | 3×3, 5×5, 7×7 común |\n",
    "\n",
    "**Para arquitectura completa:**\n",
    "$$\n",
    "\\text{FIC}_{\\text{CNN}} = -2\\log \\mathcal{L} + 2\\log\\left(\\sum_{\\text{capas}} \\Phi_{\\text{capa}}\\right) + \\sum_{\\text{capas}} k_{\\text{capa}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b52f44b",
   "metadata": {},
   "source": [
    "## $\\color{#dda}{\\text{11. Resumen de Notación Completa}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddcd3a3b",
   "metadata": {},
   "source": [
    "| Símbolo | Nombre | Descripción | Tipo |\n",
    "|---------|--------|-------------|------|\n",
    "| $\\text{FIC}$ | FIC score | Valor del criterio | escalar |\n",
    "| $\\mathcal{L}$ | Verosimilitud | Probabilidad de los datos | $[0,1]$ |\n",
    "| $\\hat{\\theta}$ | Parámetros | Estimaciones MLE/MAP | vector |\n",
    "| $\\mathcal{D}$ | Datos | Conjunto de entrenamiento | conjunto |\n",
    "| $\\Phi(f)$ | FLOPs | Operaciones de punto flotante | entero |\n",
    "| $f$ | Modelo | Función predictiva | función |\n",
    "| $\\alpha$ | Peso FLOPs | Penalización computacional | real |\n",
    "| $\\beta$ | Peso parámetros | Penalización paramétrica | real |\n",
    "| $k$ | Parámetros | Dimensión de $\\theta$ | entero |\n",
    "| $n$ | Tamaño muestra | Número de observaciones | entero |\n",
    "| $p$ | Predictores | Número de features | entero |\n",
    "| $L$ | Capas | Profundidad de red | entero |\n",
    "| $d_l$ | Neuronas | Ancho de capa $l$ | entero |\n",
    "| $\\text{RSS}$ | Residuos | Suma de errores cuadrados | real |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e030b0a",
   "metadata": {},
   "source": [
    "## $\\color{#dda}{\\text{12. Fórmula Final (RECOMENDADA)}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "976ef648",
   "metadata": {},
   "source": [
    "$$\n",
    "\\boxed{\n",
    "\\begin{aligned}\n",
    "\\text{FIC} &= -2\\log \\mathcal{L}(\\hat{\\theta}|\\mathcal{D}) + 2\\log(\\Phi(f)) + k \\\\\n",
    "&= \\underbrace{-2\\log \\mathcal{L}}_{\\text{ajuste}} + \\underbrace{2\\log(\\Phi)}_{\\text{complejidad computacional}} + \\underbrace{k}_{\\text{complejidad paramétrica}}\n",
    "\\end{aligned}\n",
    "}\n",
    "$$\n",
    "\n",
    "**Dónde:**\n",
    "- **Primer término:** Mide qué tan bien el modelo se ajusta a los datos (menor es mejor)\n",
    "- **Segundo término:** Penaliza modelos computacionalmente costosos (FLOPs altos)\n",
    "- **Tercer término:** Penaliza modelos con muchos parámetros (previene overfitting)\n",
    "\n",
    "**Interpretación:** Busca el modelo que mejor balancea ajuste, eficiencia computacional y simplicidad paramétrica."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
